# Lesson 11: Programming Bayes Rule

## Problem 
```
p(c) = p0 # PRIOR = Chance of having cancer
p(Pos|C) = p1 # SENSITIVITY = test result positive if you have cancer 
p(Neg|Not C) = p2 # SPECITIVITY = test result negative if you don't have cancer
```

1. Using f() find the chance of having cancer given the test was positive.
2. Using g() find the chance of having cancer given the test was negative.

## Solution
```
# possibility of having cancer if test is positive
def f(p0,p1,p2):
  return p0*p1 / (p0*p1 + (1-p0) * (1-p2))

print f(.1,.9,.8)
print f(.01,.7,.9)

# possibility of having cancer if test is negative
def g(p0,p1,p2):
  return p0*(1-p1) / (p0*(1-p1) + (1-p0)*p2)

print g(.1,.9,.8)
print g(.01,.7,.9)
```

Note: To get what's asked for try to make the formula match the value you'll be getting by using `1-variable` to get the reverse. This is a little vague so I'll show you an example. (I might be wrong)

```
#Return the probability of A conditioned on B given that 
#P(A)=p0, P(B|A)=p1, and P(Not B|Not A)=p2 
```

You're going to want your formula to look like
`z = x / (x + y)`

`x + y` is called a NORMALIZER
`x` and `y` are called JOINT PROBABILITY OF TWO EVENTS
`z` is called the POSTERIOR DISTRIBUTION OF HAVING CANCER GIVEN POS RESULT

YOU WANT: `p(A conditioned on B)`

LOOK AT VARS:
```
p0 = p(A)
p1 = P(B|A)
p2 = P(Not B|Not A)
```

How would you transform them to look like p(A con B)?

p0 * p1 = looks like P(A c B) so that's your x

For p2 its a bit trickier:

Observe p(Not B|Not A). It's a double negative, you're looking for something that looks like p(A c B)

So we'll invert both shit.

`y = 1-p0 * 1-p2 `

FINAL ANS: `p0 * p1 / ((p0 * p1) + (1-p0) * (1-p2))`

It may be vague but its the only way I understand it.



## Notes

Write probability of x conditioned on y as 
`P(x|y)`

Parentheses are super important
```
from __future__ import division
"""
p(A) = .01
p(Pos|A) = .9
p(Neg|Not A) = .9

Find P(A|Pos)
"""

p0 = .01
p1 = .9
p2 = .9

x = p0 * p1 # JOINT
y = (1-p0) * (1-p2) # JOIN

print x, y

posterior1 =  x / (x + y) # NORMALIZE
posterior2 =  y / (x+y)

print "MUST BE TRUE", posterior1 + posterior2 == 1 # DONT FORGET TO TEST

```

## Real steps

1. Get 1-x of all variables, label as such
```
Given:
PRIOR = P(C) = .01
SENSITIVITY = P(Pos|C) = .9
SPECITIVITY = P(Neg|not C) = .9

Want:
P(not C) = .99
P(Neg|C) = .1
P(Pos|not C) = .1
```

Note that 1-x results in the opposite test.

2. Get joint probability 
```
Test = what if you got negative?

P(C, Neg) = P(C) * P(Neg|C)
P(not C, Neg) = P(not C) * P(Neg|not C)
```
3. Get the normalizer

```
Just add the two results above.
```

Notation: Will come out as P(test) so P(Negative)

4. Get the posterior

Remember the joint probabilities you got?

P(C|Neg) = P(C, Neg) / normalizer
P(not C, Neg) = P(not C, Neg) / normalizer
